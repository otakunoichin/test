{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkaXnodEealWtlYssVI4AH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otakunoichin/test/blob/main/Ai%E7%B6%B2%E8%86%9CwhiteAddResult.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 完全版：1M vs 1Y 変化量比較（モデルロード込み）=====\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAzAjMs_Uy0y",
        "outputId": "aaf8cef3-fc6e-4bcf-8dbb-54b7ec3f8ef8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 設定\n",
        "# -------------------------\n",
        "ROOT = \"/content/drive/MyDrive/AiFundas\"\n",
        "\n",
        "pairs = [\n",
        "    (\"pt1_1M.png\",   \"pt1_1Y.png\"),\n",
        "    (\"pt13R_1M.png\", \"pt13R_1Y.png\"),\n",
        "    (\"pt21R_1M.png\", \"pt21R_1Y.png\"),\n",
        "    (\"pt27R_1M.png\", \"pt27R_1Y.png\"),\n",
        "]"
      ],
      "metadata": {
        "id": "Nprm1Ox8Wegd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ★白学習済みモデル\n",
        "CKPT_PATH = os.path.join(ROOT, \"best_unet_with_white.pt\")\n",
        "# もし無いなら旧モデルに切り替える\n",
        "if not os.path.exists(CKPT_PATH):\n",
        "    CKPT_PATH = os.path.join(ROOT, \"best_unet.pt\")\n",
        "print(\"using ckpt:\", CKPT_PATH)\n",
        "\n",
        "OUT_DIR = os.path.join(ROOT, \"followup_results_v2\")  # 新しい保存先（消してもOK）\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "THR = 0.5\n",
        "ALPHA = 0.35\n",
        "TARGET_SIZE = 4096\n",
        "PATCH_SIZE  = 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4U0U-JkWeiy",
        "outputId": "4cd29202-682c-46ba-b5b2-e9e3b42e4006"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using ckpt: /content/drive/MyDrive/AiFundas/best_unet_with_white.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 画像読み込み\n",
        "# -------------------------\n",
        "def load_gray_u8(path):\n",
        "    return np.array(Image.open(path).convert(\"L\"), dtype=np.uint8)\n",
        "\n",
        "# -------------------------\n",
        "# UNet（state_dictロード用に必要）\n",
        "# -------------------------\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=1, base=32):\n",
        "        super().__init__()\n",
        "        self.enc1 = DoubleConv(in_ch, base);    self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = DoubleConv(base, base*2);   self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = DoubleConv(base*2, base*4); self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = DoubleConv(base*4, base*8); self.pool4 = nn.MaxPool2d(2)\n",
        "        self.bottleneck = DoubleConv(base*8, base*16)\n",
        "        self.up4 = nn.ConvTranspose2d(base*16, base*8, 2, stride=2); self.dec4 = DoubleConv(base*16, base*8)\n",
        "        self.up3 = nn.ConvTranspose2d(base*8,  base*4, 2, stride=2); self.dec3 = DoubleConv(base*8,  base*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base*4,  base*2, 2, stride=2); self.dec2 = DoubleConv(base*4,  base*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base*2,  base,   2, stride=2); self.dec1 = DoubleConv(base*2,  base)\n",
        "        self.outc = nn.Conv2d(base, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "        b  = self.bottleneck(self.pool4(e4))\n",
        "        d4 = self.up4(b); d4 = torch.cat([d4, e4], dim=1); d4 = self.dec4(d4)\n",
        "        d3 = self.up3(d4); d3 = torch.cat([d3, e3], dim=1); d3 = self.dec3(d3)\n",
        "        d2 = self.up2(d3); d2 = torch.cat([d2, e2], dim=1); d2 = self.dec2(d2)\n",
        "        d1 = self.up1(d2); d1 = torch.cat([d1, e1], dim=1); d1 = self.dec1(d1)\n",
        "        return self.outc(d1)"
      ],
      "metadata": {
        "id": "WbDfEU37Welc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# device & モデルロード\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=device)\n",
        "state_dict = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
        "\n",
        "model = UNet(in_ch=1, out_ch=1, base=32).to(device)\n",
        "model.load_state_dict(state_dict, strict=True)\n",
        "model.eval()\n",
        "print(\"model loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHLd9mQVZcQF",
        "outputId": "84c20d8b-2e9d-49e8-c51e-a172b6036dae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 4096pad→512推論\n",
        "# -------------------------\n",
        "def reflect_pad_to(arr, target=4096):\n",
        "    h, w = arr.shape\n",
        "    if h > target or w > target:\n",
        "        raise ValueError(f\"image too large: {arr.shape} > {target}\")\n",
        "    pad_h = target - h\n",
        "    pad_w = target - w\n",
        "    top = pad_h // 2\n",
        "    bottom = pad_h - top\n",
        "    left = pad_w // 2\n",
        "    right = pad_w - left\n",
        "    arr_pad = np.pad(arr, ((top, bottom), (left, right)), mode=\"reflect\")\n",
        "    return arr_pad, (top, left, h, w)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_mask(gray_u8, thr=0.5):\n",
        "    H, W = gray_u8.shape\n",
        "    img_pad, (top, left, h, w) = reflect_pad_to(gray_u8, TARGET_SIZE)\n",
        "    prob_canvas = np.zeros((TARGET_SIZE, TARGET_SIZE), dtype=np.float32)\n",
        "\n",
        "    for r in range(TARGET_SIZE // PATCH_SIZE):\n",
        "        for c in range(TARGET_SIZE // PATCH_SIZE):\n",
        "            y0 = r * PATCH_SIZE\n",
        "            x0 = c * PATCH_SIZE\n",
        "            patch = img_pad[y0:y0+PATCH_SIZE, x0:x0+PATCH_SIZE].astype(np.float32) / 255.0\n",
        "            x = torch.from_numpy(patch).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            logits = model(x)\n",
        "            prob = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
        "            prob_canvas[y0:y0+PATCH_SIZE, x0:x0+PATCH_SIZE] = prob\n",
        "\n",
        "    prob_crop = prob_canvas[top:top+h, left:left+w]\n",
        "    mask01 = (prob_crop > thr).astype(np.uint8)\n",
        "    return prob_crop, mask01\n"
      ],
      "metadata": {
        "id": "VbsjcIvLZcSs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# ECC（1Yを1Mへ合わせる）\n",
        "# -------------------------\n",
        "def normalize_u8(img_u8):\n",
        "    img = img_u8.astype(np.float32)\n",
        "    mn, mx = np.percentile(img, 1), np.percentile(img, 99)\n",
        "    img = np.clip(img, mn, mx)\n",
        "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "    return (img * 255).astype(np.uint8)\n",
        "\n",
        "def register_ecc(ref_u8, mov_u8, warp_mode=cv2.MOTION_AFFINE, iters=300, eps=1e-6):\n",
        "    ref_f = ref_u8.astype(np.float32)\n",
        "    mov_f = mov_u8.astype(np.float32)\n",
        "\n",
        "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
        "        warp = np.eye(3, 3, dtype=np.float32)\n",
        "    else:\n",
        "        warp = np.eye(2, 3, dtype=np.float32)\n",
        "\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, iters, eps)\n",
        "    cc, warp = cv2.findTransformECC(ref_f, mov_f, warp, warp_mode, criteria)\n",
        "    return warp, float(cc)\n",
        "\n",
        "def warp_image(img_u8, ref_shape_hw, warp, warp_mode=cv2.MOTION_AFFINE):\n",
        "    h, w = ref_shape_hw\n",
        "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
        "        return cv2.warpPerspective(img_u8, warp, (w, h),\n",
        "                                   flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
        "    else:\n",
        "        return cv2.warpAffine(img_u8, warp, (w, h),\n",
        "                              flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)"
      ],
      "metadata": {
        "id": "B5phasGsZcVI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# overlay（元画像はそのまま + 赤半透明）\n",
        "# -------------------------\n",
        "def overlay_on_gray(img_u8, mask01, alpha=0.35):\n",
        "    img_rgb = np.stack([img_u8]*3, axis=-1).astype(np.float32)\n",
        "    red = np.zeros_like(img_rgb); red[..., 0] = 255\n",
        "    m3 = np.stack([mask01]*3, axis=-1)\n",
        "    out = img_rgb.copy()\n",
        "    out[m3 == 1] = out[m3 == 1] * (1 - alpha) + red[m3 == 1] * alpha\n",
        "    return out.astype(np.uint8)"
      ],
      "metadata": {
        "id": "jdv3xQTtZcX4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 実行：CSV + 8枚overlay保存\n",
        "# -------------------------\n",
        "rows = []\n",
        "\n",
        "for f1M, f1Y in pairs:\n",
        "    case = f1M.replace(\"_1M.png\", \"\")\n",
        "\n",
        "    p1 = os.path.join(ROOT, f1M)\n",
        "    p2 = os.path.join(ROOT, f1Y)\n",
        "    assert os.path.exists(p1) and os.path.exists(p2), f\"missing file: {f1M} or {f1Y}\"\n",
        "\n",
        "    img1M = load_gray_u8(p1)\n",
        "    img1Y = load_gray_u8(p2)\n",
        "\n",
        "    # ECC registration（基本AFFINE、失敗したらHOMOGRAPHY）\n",
        "    warp_mode = cv2.MOTION_AFFINE\n",
        "    try:\n",
        "        warp, cc = register_ecc(normalize_u8(img1M), normalize_u8(img1Y), warp_mode=warp_mode)\n",
        "        img1Y_aligned = warp_image(img1Y, img1M.shape, warp, warp_mode=warp_mode)\n",
        "    except cv2.error:\n",
        "        warp_mode = cv2.MOTION_HOMOGRAPHY\n",
        "        warp, cc = register_ecc(normalize_u8(img1M), normalize_u8(img1Y), warp_mode=warp_mode)\n",
        "        img1Y_aligned = warp_image(img1Y, img1M.shape, warp, warp_mode=warp_mode)\n",
        "\n",
        "    # segmentation\n",
        "    _, maskM = predict_mask(img1M, thr=THR)\n",
        "    _, maskY = predict_mask(img1Y_aligned, thr=THR)\n",
        "\n",
        "    areaM = int(maskM.sum())\n",
        "    areaY = int(maskY.sum())\n",
        "\n",
        "    rows.append({\n",
        "        \"case\": case,\n",
        "        \"file_1M\": f1M,\n",
        "        \"file_1Y\": f1Y,\n",
        "        \"ecc_cc\": cc,\n",
        "        \"warp_mode\": \"AFFINE\" if warp_mode == cv2.MOTION_AFFINE else \"HOMOGRAPHY\",\n",
        "        \"area_1M\": areaM,\n",
        "        \"area_1Y\": areaY,\n",
        "        \"area_delta\": areaY - areaM,\n",
        "        \"area_ratio\": areaY / (areaM + 1e-8),\n",
        "    })\n",
        "\n",
        "    # overlay保存（元画像はそのまま + 赤半透明）\n",
        "    ovM = overlay_on_gray(img1M, maskM, alpha=ALPHA)\n",
        "    ovY = overlay_on_gray(img1Y_aligned, maskY, alpha=ALPHA)\n",
        "\n",
        "    Image.fromarray(ovM).save(os.path.join(OUT_DIR, f\"{case}_1M_overlay.png\"))\n",
        "    Image.fromarray(ovY).save(os.path.join(OUT_DIR, f\"{case}_1Y_overlay.png\"))\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"case\")\n",
        "csv_path = os.path.join(OUT_DIR, \"followup_change_summary.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"saved:\", csv_path)\n",
        "display(df)\n",
        "\n",
        "print(\"overlay saved to:\", OUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "iwPf7dmgZo0u",
        "outputId": "bd0d16c8-f98e-4ec5-d0b2-b6970f50796d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved: /content/drive/MyDrive/AiFundas/followup_results_v2/followup_change_summary.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    case       file_1M       file_1Y    ecc_cc warp_mode  area_1M  area_1Y  \\\n",
              "0    pt1    pt1_1M.png    pt1_1Y.png  0.937967    AFFINE  4650028  4140144   \n",
              "1  pt13R  pt13R_1M.png  pt13R_1Y.png  0.956527    AFFINE  3887638  3520596   \n",
              "2  pt21R  pt21R_1M.png  pt21R_1Y.png  0.924565    AFFINE  3566347  3770612   \n",
              "3  pt27R  pt27R_1M.png  pt27R_1Y.png  0.963204    AFFINE  3844098  3742250   \n",
              "\n",
              "   area_delta  area_ratio  \n",
              "0     -509884    0.890348  \n",
              "1     -367042    0.905587  \n",
              "2      204265    1.057276  \n",
              "3     -101848    0.973505  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd45eea8-155e-458c-9c30-f0f7ab549ff7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case</th>\n",
              "      <th>file_1M</th>\n",
              "      <th>file_1Y</th>\n",
              "      <th>ecc_cc</th>\n",
              "      <th>warp_mode</th>\n",
              "      <th>area_1M</th>\n",
              "      <th>area_1Y</th>\n",
              "      <th>area_delta</th>\n",
              "      <th>area_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pt1</td>\n",
              "      <td>pt1_1M.png</td>\n",
              "      <td>pt1_1Y.png</td>\n",
              "      <td>0.937967</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>4650028</td>\n",
              "      <td>4140144</td>\n",
              "      <td>-509884</td>\n",
              "      <td>0.890348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pt13R</td>\n",
              "      <td>pt13R_1M.png</td>\n",
              "      <td>pt13R_1Y.png</td>\n",
              "      <td>0.956527</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3887638</td>\n",
              "      <td>3520596</td>\n",
              "      <td>-367042</td>\n",
              "      <td>0.905587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pt21R</td>\n",
              "      <td>pt21R_1M.png</td>\n",
              "      <td>pt21R_1Y.png</td>\n",
              "      <td>0.924565</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3566347</td>\n",
              "      <td>3770612</td>\n",
              "      <td>204265</td>\n",
              "      <td>1.057276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pt27R</td>\n",
              "      <td>pt27R_1M.png</td>\n",
              "      <td>pt27R_1Y.png</td>\n",
              "      <td>0.963204</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3844098</td>\n",
              "      <td>3742250</td>\n",
              "      <td>-101848</td>\n",
              "      <td>0.973505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd45eea8-155e-458c-9c30-f0f7ab549ff7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd45eea8-155e-458c-9c30-f0f7ab549ff7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd45eea8-155e-458c-9c30-f0f7ab549ff7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_176d4da5-d792-4647-8c72-64e6ab011e0d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_176d4da5-d792-4647-8c72-64e6ab011e0d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"case\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pt13R\",\n          \"pt27R\",\n          \"pt1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_1M\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pt13R_1M.png\",\n          \"pt27R_1M.png\",\n          \"pt1_1M.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_1Y\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pt13R_1Y.png\",\n          \"pt27R_1Y.png\",\n          \"pt1_1Y.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecc_cc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017607059187582933,\n        \"min\": 0.9245649990767872,\n        \"max\": 0.9632039814472902,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9565268482844995,\n          0.9632039814472902,\n          0.9379669885098603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"warp_mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AFFINE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_1M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 464345,\n        \"min\": 3566347,\n        \"max\": 4650028,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3887638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_1Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 256767,\n        \"min\": 3520596,\n        \"max\": 4140144,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3520596\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 314554,\n        \"min\": -509884,\n        \"max\": 204265,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -367042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0761860643929433,\n        \"min\": 0.8903481871506991,\n        \"max\": 1.0572756941486596,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9055874029423499\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overlay saved to: /content/drive/MyDrive/AiFundas/followup_results_v2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l1wLnJMZZo3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uIECi8mZcZ7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}