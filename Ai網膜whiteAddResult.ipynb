{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMAZgF/8Lv1C+JDWMVs6Xzy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otakunoichin/test/blob/main/Ai%E7%B6%B2%E8%86%9CwhiteAddResult.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 完全版：1M vs 1Y 変化量比較（モデルロード込み）=====\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAzAjMs_Uy0y",
        "outputId": "71c519e8-ed4c-490b-efbc-84ffe6442bd5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 設定\n",
        "# -------------------------\n",
        "ROOT = \"/content/drive/MyDrive/AiFundas\"\n",
        "\n",
        "pairs = [\n",
        "    (\"pt1_1M.png\",   \"pt1_1Y.png\"),\n",
        "    (\"pt13R_1M.png\", \"pt13R_1Y.png\"),\n",
        "    (\"pt21R_1M.png\", \"pt21R_1Y.png\"),\n",
        "    (\"pt27R_1M.png\", \"pt27R_1Y.png\"),\n",
        "]"
      ],
      "metadata": {
        "id": "Nprm1Ox8Wegd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ★白学習済みモデル\n",
        "CKPT_PATH = os.path.join(ROOT, \"best_unet_with_white.pt\")\n",
        "# もし無いなら旧モデルに切り替える\n",
        "if not os.path.exists(CKPT_PATH):\n",
        "    CKPT_PATH = os.path.join(ROOT, \"best_unet.pt\")\n",
        "print(\"using ckpt:\", CKPT_PATH)\n",
        "\n",
        "OUT_DIR = os.path.join(ROOT, \"followup_results_v2\")  # 新しい保存先（消してもOK）\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "THR = 0.65\n",
        "ALPHA = 0.35\n",
        "TARGET_SIZE = 4096\n",
        "PATCH_SIZE  = 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4U0U-JkWeiy",
        "outputId": "8e7f65cc-c4aa-4c76-d54d-e32e8ade9e85"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using ckpt: /content/drive/MyDrive/AiFundas/best_unet_with_white.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjZuFOxjRczD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G0ik4EunRc8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 画像読み込み\n",
        "# -------------------------\n",
        "def load_gray_u8(path):\n",
        "    return np.array(Image.open(path).convert(\"L\"), dtype=np.uint8)\n",
        "\n",
        "# -------------------------\n",
        "# UNet（state_dictロード用に必要）\n",
        "# -------------------------\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=1, base=32):\n",
        "        super().__init__()\n",
        "        self.enc1 = DoubleConv(in_ch, base);    self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = DoubleConv(base, base*2);   self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = DoubleConv(base*2, base*4); self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = DoubleConv(base*4, base*8); self.pool4 = nn.MaxPool2d(2)\n",
        "        self.bottleneck = DoubleConv(base*8, base*16)\n",
        "        self.up4 = nn.ConvTranspose2d(base*16, base*8, 2, stride=2); self.dec4 = DoubleConv(base*16, base*8)\n",
        "        self.up3 = nn.ConvTranspose2d(base*8,  base*4, 2, stride=2); self.dec3 = DoubleConv(base*8,  base*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base*4,  base*2, 2, stride=2); self.dec2 = DoubleConv(base*4,  base*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base*2,  base,   2, stride=2); self.dec1 = DoubleConv(base*2,  base)\n",
        "        self.outc = nn.Conv2d(base, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "        b  = self.bottleneck(self.pool4(e4))\n",
        "        d4 = self.up4(b); d4 = torch.cat([d4, e4], dim=1); d4 = self.dec4(d4)\n",
        "        d3 = self.up3(d4); d3 = torch.cat([d3, e3], dim=1); d3 = self.dec3(d3)\n",
        "        d2 = self.up2(d3); d2 = torch.cat([d2, e2], dim=1); d2 = self.dec2(d2)\n",
        "        d1 = self.up1(d2); d1 = torch.cat([d1, e1], dim=1); d1 = self.dec1(d1)\n",
        "        return self.outc(d1)"
      ],
      "metadata": {
        "id": "WbDfEU37Welc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# device & モデルロード\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "ckpt = torch.load(CKPT_PATH, map_location=device)\n",
        "state_dict = ckpt[\"model\"] if isinstance(ckpt, dict) and \"model\" in ckpt else ckpt\n",
        "\n",
        "model = UNet(in_ch=1, out_ch=1, base=32).to(device)\n",
        "model.load_state_dict(state_dict, strict=True)\n",
        "model.eval()\n",
        "print(\"model loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHLd9mQVZcQF",
        "outputId": "da0fd11d-b145-4719-d16c-11af24b6ea52"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aNIvDGRMQWKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P9dipN_eQW1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 4096pad→512推論\n",
        "# -------------------------\n",
        "def reflect_pad_to(arr, target=4096):\n",
        "    h, w = arr.shape\n",
        "    if h > target or w > target:\n",
        "        raise ValueError(f\"image too large: {arr.shape} > {target}\")\n",
        "    pad_h = target - h\n",
        "    pad_w = target - w\n",
        "    top = pad_h // 2\n",
        "    bottom = pad_h - top\n",
        "    left = pad_w // 2\n",
        "    right = pad_w - left\n",
        "    arr_pad = np.pad(arr, ((top, bottom), (left, right)), mode=\"reflect\")\n",
        "    return arr_pad, (top, left, h, w)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_mask(gray_u8, thr=0.5):\n",
        "    H, W = gray_u8.shape\n",
        "    img_pad, (top, left, h, w) = reflect_pad_to(gray_u8, TARGET_SIZE)\n",
        "    prob_canvas = np.zeros((TARGET_SIZE, TARGET_SIZE), dtype=np.float32)\n",
        "\n",
        "    for r in range(TARGET_SIZE // PATCH_SIZE):\n",
        "        for c in range(TARGET_SIZE // PATCH_SIZE):\n",
        "            y0 = r * PATCH_SIZE\n",
        "            x0 = c * PATCH_SIZE\n",
        "            patch = img_pad[y0:y0+PATCH_SIZE, x0:x0+PATCH_SIZE].astype(np.float32) / 255.0\n",
        "            x = torch.from_numpy(patch).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            logits = model(x)\n",
        "            prob = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
        "            prob_canvas[y0:y0+PATCH_SIZE, x0:x0+PATCH_SIZE] = prob\n",
        "\n",
        "    prob_crop = prob_canvas[top:top+h, left:left+w]\n",
        "    mask01 = (prob_crop > thr).astype(np.uint8)\n",
        "    return prob_crop, mask01\n"
      ],
      "metadata": {
        "id": "VbsjcIvLZcSs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# ECC（1Yを1Mへ合わせる）\n",
        "# -------------------------\n",
        "def normalize_u8(img_u8):\n",
        "    img = img_u8.astype(np.float32)\n",
        "    mn, mx = np.percentile(img, 1), np.percentile(img, 99)\n",
        "    img = np.clip(img, mn, mx)\n",
        "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "    return (img * 255).astype(np.uint8)\n",
        "\n",
        "def register_ecc(ref_u8, mov_u8, warp_mode=cv2.MOTION_AFFINE, iters=300, eps=1e-6):\n",
        "    ref_f = ref_u8.astype(np.float32)\n",
        "    mov_f = mov_u8.astype(np.float32)\n",
        "\n",
        "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
        "        warp = np.eye(3, 3, dtype=np.float32)\n",
        "    else:\n",
        "        warp = np.eye(2, 3, dtype=np.float32)\n",
        "\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, iters, eps)\n",
        "    cc, warp = cv2.findTransformECC(ref_f, mov_f, warp, warp_mode, criteria)\n",
        "    return warp, float(cc)\n",
        "\n",
        "def warp_image(img_u8, ref_shape_hw, warp, warp_mode=cv2.MOTION_AFFINE):\n",
        "    h, w = ref_shape_hw\n",
        "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
        "        return cv2.warpPerspective(img_u8, warp, (w, h),\n",
        "                                   flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
        "    else:\n",
        "        return cv2.warpAffine(img_u8, warp, (w, h),\n",
        "                              flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)"
      ],
      "metadata": {
        "id": "B5phasGsZcVI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vIVBbBY2QfNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_neFrS5QfWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# overlay（元画像はそのまま + 赤半透明）\n",
        "# -------------------------\n",
        "def overlay_on_gray(img_u8, mask01, alpha=0.35):\n",
        "    img_rgb = np.stack([img_u8]*3, axis=-1).astype(np.float32)\n",
        "    red = np.zeros_like(img_rgb); red[..., 0] = 255\n",
        "    m3 = np.stack([mask01]*3, axis=-1)\n",
        "    out = img_rgb.copy()\n",
        "    out[m3 == 1] = out[m3 == 1] * (1 - alpha) + red[m3 == 1] * alpha\n",
        "    return out.astype(np.uint8)"
      ],
      "metadata": {
        "id": "jdv3xQTtZcX4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZQRDoLLZQu5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T2tsr3zPQvGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 実行：CSV + 8枚overlay保存\n",
        "# -------------------------\n",
        "rows = []\n",
        "\n",
        "for f1M, f1Y in pairs:\n",
        "    case = f1M.replace(\"_1M.png\", \"\")\n",
        "\n",
        "    p1 = os.path.join(ROOT, f1M)\n",
        "    p2 = os.path.join(ROOT, f1Y)\n",
        "    assert os.path.exists(p1) and os.path.exists(p2), f\"missing file: {f1M} or {f1Y}\"\n",
        "\n",
        "    img1M = load_gray_u8(p1)\n",
        "    img1Y = load_gray_u8(p2)\n",
        "\n",
        "    # ECC registration（基本AFFINE、失敗したらHOMOGRAPHY）\n",
        "    warp_mode = cv2.MOTION_AFFINE\n",
        "    try:\n",
        "        warp, cc = register_ecc(normalize_u8(img1M), normalize_u8(img1Y), warp_mode=warp_mode)\n",
        "        img1Y_aligned = warp_image(img1Y, img1M.shape, warp, warp_mode=warp_mode)\n",
        "    except cv2.error:\n",
        "        warp_mode = cv2.MOTION_HOMOGRAPHY\n",
        "        warp, cc = register_ecc(normalize_u8(img1M), normalize_u8(img1Y), warp_mode=warp_mode)\n",
        "        img1Y_aligned = warp_image(img1Y, img1M.shape, warp, warp_mode=warp_mode)\n",
        "\n",
        "    # segmentation\n",
        "    _, maskM = predict_mask(img1M, thr=THR)\n",
        "    _, maskY = predict_mask(img1Y_aligned, thr=THR)\n",
        "\n",
        "    areaM = int(maskM.sum())\n",
        "    areaY = int(maskY.sum())\n",
        "\n",
        "    rows.append({\n",
        "        \"case\": case,\n",
        "        \"file_1M\": f1M,\n",
        "        \"file_1Y\": f1Y,\n",
        "        \"ecc_cc\": cc,\n",
        "        \"warp_mode\": \"AFFINE\" if warp_mode == cv2.MOTION_AFFINE else \"HOMOGRAPHY\",\n",
        "        \"area_1M\": areaM,\n",
        "        \"area_1Y\": areaY,\n",
        "        \"area_delta\": areaY - areaM,\n",
        "        \"area_ratio\": areaY / (areaM + 1e-8),\n",
        "    })\n",
        "\n",
        "    # overlay保存（元画像はそのまま + 赤半透明）\n",
        "    ovM = overlay_on_gray(img1M, maskM, alpha=ALPHA)\n",
        "    ovY = overlay_on_gray(img1Y_aligned, maskY, alpha=ALPHA)\n",
        "\n",
        "    Image.fromarray(ovM).save(os.path.join(OUT_DIR, f\"{case}_1M_overlay.png\"))\n",
        "    Image.fromarray(ovY).save(os.path.join(OUT_DIR, f\"{case}_1Y_overlay.png\"))\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"case\")\n",
        "csv_path = os.path.join(OUT_DIR, \"followup_change_summary.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"saved:\", csv_path)\n",
        "display(df)\n",
        "\n",
        "print(\"overlay saved to:\", OUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "iwPf7dmgZo0u",
        "outputId": "a17adf07-f6b8-4bd3-b6c2-d4441e5b4dce"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved: /content/drive/MyDrive/AiFundas/followup_results_v2/followup_change_summary.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    case       file_1M       file_1Y    ecc_cc warp_mode  area_1M  area_1Y  \\\n",
              "0    pt1    pt1_1M.png    pt1_1Y.png  0.937967    AFFINE  4578053  4074318   \n",
              "1  pt13R  pt13R_1M.png  pt13R_1Y.png  0.956527    AFFINE  3899164  3575967   \n",
              "2  pt21R  pt21R_1M.png  pt21R_1Y.png  0.924565    AFFINE  3562974  3739858   \n",
              "3  pt27R  pt27R_1M.png  pt27R_1Y.png  0.963204    AFFINE  3836357  3692488   \n",
              "\n",
              "   area_delta  area_ratio  \n",
              "0     -503735    0.889967  \n",
              "1     -323197    0.917111  \n",
              "2      176884    1.049645  \n",
              "3     -143869    0.962499  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80ffb7f9-525f-445f-baa7-2559d0a4372f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case</th>\n",
              "      <th>file_1M</th>\n",
              "      <th>file_1Y</th>\n",
              "      <th>ecc_cc</th>\n",
              "      <th>warp_mode</th>\n",
              "      <th>area_1M</th>\n",
              "      <th>area_1Y</th>\n",
              "      <th>area_delta</th>\n",
              "      <th>area_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pt1</td>\n",
              "      <td>pt1_1M.png</td>\n",
              "      <td>pt1_1Y.png</td>\n",
              "      <td>0.937967</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>4578053</td>\n",
              "      <td>4074318</td>\n",
              "      <td>-503735</td>\n",
              "      <td>0.889967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pt13R</td>\n",
              "      <td>pt13R_1M.png</td>\n",
              "      <td>pt13R_1Y.png</td>\n",
              "      <td>0.956527</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3899164</td>\n",
              "      <td>3575967</td>\n",
              "      <td>-323197</td>\n",
              "      <td>0.917111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pt21R</td>\n",
              "      <td>pt21R_1M.png</td>\n",
              "      <td>pt21R_1Y.png</td>\n",
              "      <td>0.924565</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3562974</td>\n",
              "      <td>3739858</td>\n",
              "      <td>176884</td>\n",
              "      <td>1.049645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pt27R</td>\n",
              "      <td>pt27R_1M.png</td>\n",
              "      <td>pt27R_1Y.png</td>\n",
              "      <td>0.963204</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3836357</td>\n",
              "      <td>3692488</td>\n",
              "      <td>-143869</td>\n",
              "      <td>0.962499</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80ffb7f9-525f-445f-baa7-2559d0a4372f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80ffb7f9-525f-445f-baa7-2559d0a4372f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80ffb7f9-525f-445f-baa7-2559d0a4372f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_3515b5ae-c9d5-4ed5-a861-6acb3cee6a81\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3515b5ae-c9d5-4ed5-a861-6acb3cee6a81 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"case\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pt13R\",\n          \"pt27R\",\n          \"pt1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_1M\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pt13R_1M.png\",\n          \"pt27R_1M.png\",\n          \"pt1_1M.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_1Y\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pt13R_1Y.png\",\n          \"pt27R_1Y.png\",\n          \"pt1_1Y.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecc_cc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017607059187582933,\n        \"min\": 0.9245649990767872,\n        \"max\": 0.9632039814472902,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9565268482844995,\n          0.9632039814472902,\n          0.9379669885098603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"warp_mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AFFINE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_1M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 431382,\n        \"min\": 3562974,\n        \"max\": 4578053,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3899164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_1Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 213832,\n        \"min\": 3575967,\n        \"max\": 4074318,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3575967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 290181,\n        \"min\": -503735,\n        \"max\": 176884,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -323197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"area_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06994893075638071,\n        \"min\": 0.8899674162793639,\n        \"max\": 1.0496450437190925,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9171112064021906\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overlay saved to: /content/drive/MyDrive/AiFundas/followup_results_v2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#旧モデル、新モデル比較\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/AiFundas\"\n",
        "\n",
        "pairs = [\n",
        "    (\"pt1_1M.png\",   \"pt1_1Y.png\"),\n",
        "    (\"pt13R_1M.png\", \"pt13R_1Y.png\"),\n",
        "    (\"pt21R_1M.png\", \"pt21R_1Y.png\"),\n",
        "    (\"pt27R_1M.png\", \"pt27R_1Y.png\"),\n",
        "]\n",
        "\n",
        "OLD_CKPT = os.path.join(ROOT, \"best_unet.pt\")\n",
        "NEW_CKPT = os.path.join(ROOT, \"best_unet_with_white.pt\")\n",
        "assert os.path.exists(OLD_CKPT), f\"missing: {OLD_CKPT}\"\n",
        "assert os.path.exists(NEW_CKPT), f\"missing: {NEW_CKPT}\"\n",
        "\n",
        "OUT_DIR = os.path.join(ROOT, \"followup_compare_old_vs_new\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "THR = 0.65\n",
        "ALPHA = 0.35\n",
        "TARGET_SIZE = 4096\n",
        "PATCH_SIZE  = 512\n",
        "\n",
        "# -------------------------\n",
        "# utils\n",
        "# -------------------------\n",
        "def load_gray_u8(path):\n",
        "    return np.array(Image.open(path).convert(\"L\"), dtype=np.uint8)\n",
        "\n",
        "def overlay_on_gray(img_u8, mask01, alpha=0.35):\n",
        "    img_rgb = np.stack([img_u8]*3, axis=-1).astype(np.float32)\n",
        "    red = np.zeros_like(img_rgb); red[..., 0] = 255\n",
        "    m3 = np.stack([mask01]*3, axis=-1)\n",
        "    out = img_rgb.copy()\n",
        "    out[m3 == 1] = out[m3 == 1]*(1-alpha) + red[m3 == 1]*alpha\n",
        "    return out.astype(np.uint8)\n",
        "\n",
        "def normalize_u8(img_u8):\n",
        "    img = img_u8.astype(np.float32)\n",
        "    mn, mx = np.percentile(img, 1), np.percentile(img, 99)\n",
        "    img = np.clip(img, mn, mx)\n",
        "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
        "    return (img * 255).astype(np.uint8)\n",
        "\n",
        "def register_ecc(ref_u8, mov_u8, warp_mode=cv2.MOTION_AFFINE, iters=300, eps=1e-6):\n",
        "    ref_f = ref_u8.astype(np.float32)\n",
        "    mov_f = mov_u8.astype(np.float32)\n",
        "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
        "        warp = np.eye(3, 3, dtype=np.float32)\n",
        "    else:\n",
        "        warp = np.eye(2, 3, dtype=np.float32)\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, iters, eps)\n",
        "    cc, warp = cv2.findTransformECC(ref_f, mov_f, warp, warp_mode, criteria)\n",
        "    return warp, float(cc)\n",
        "\n",
        "def warp_image(img_u8, ref_shape_hw, warp, warp_mode=cv2.MOTION_AFFINE):\n",
        "    h, w = ref_shape_hw\n",
        "    if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
        "        return cv2.warpPerspective(img_u8, warp, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
        "    else:\n",
        "        return cv2.warpAffine(img_u8, warp, (w, h), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
        "\n",
        "def reflect_pad_to(arr, target=4096):\n",
        "    h, w = arr.shape\n",
        "    pad_h = target - h\n",
        "    pad_w = target - w\n",
        "    top = pad_h // 2\n",
        "    bottom = pad_h - top\n",
        "    left = pad_w // 2\n",
        "    right = pad_w - left\n",
        "    arr_pad = np.pad(arr, ((top, bottom), (left, right)), mode=\"reflect\")\n",
        "    return arr_pad, (top, left, h, w)\n",
        "\n",
        "# -------------------------\n",
        "# UNet def\n",
        "# -------------------------\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=1, out_ch=1, base=32):\n",
        "        super().__init__()\n",
        "        self.enc1 = DoubleConv(in_ch, base);    self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = DoubleConv(base, base*2);   self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = DoubleConv(base*2, base*4); self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = DoubleConv(base*4, base*8); self.pool4 = nn.MaxPool2d(2)\n",
        "        self.bottleneck = DoubleConv(base*8, base*16)\n",
        "        self.up4 = nn.ConvTranspose2d(base*16, base*8, 2, stride=2); self.dec4 = DoubleConv(base*16, base*8)\n",
        "        self.up3 = nn.ConvTranspose2d(base*8,  base*4, 2, stride=2); self.dec3 = DoubleConv(base*8,  base*4)\n",
        "        self.up2 = nn.ConvTranspose2d(base*4,  base*2, 2, stride=2); self.dec2 = DoubleConv(base*4,  base*2)\n",
        "        self.up1 = nn.ConvTranspose2d(base*2,  base,   2, stride=2); self.dec1 = DoubleConv(base*2,  base)\n",
        "        self.outc = nn.Conv2d(base, out_ch, 1)\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "        e4 = self.enc4(self.pool3(e3))\n",
        "        b  = self.bottleneck(self.pool4(e4))\n",
        "        d4 = self.up4(b); d4 = torch.cat([d4, e4], dim=1); d4 = self.dec4(d4)\n",
        "        d3 = self.up3(d4); d3 = torch.cat([d3, e3], dim=1); d3 = self.dec3(d3)\n",
        "        d2 = self.up2(d3); d2 = torch.cat([d2, e2], dim=1); d2 = self.dec2(d2)\n",
        "        d1 = self.up1(d2); d1 = torch.cat([d1, e1], dim=1); d1 = self.dec1(d1)\n",
        "        return self.outc(d1)\n",
        "\n",
        "# -------------------------\n",
        "# load models\n",
        "# -------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "def load_model(ckpt_path):\n",
        "    ck = torch.load(ckpt_path, map_location=device)\n",
        "    sd = ck[\"model\"] if isinstance(ck, dict) and \"model\" in ck else ck\n",
        "    m = UNet(in_ch=1, out_ch=1, base=32).to(device)\n",
        "    m.load_state_dict(sd, strict=True)\n",
        "    m.eval()\n",
        "    return m\n",
        "\n",
        "old_model = load_model(OLD_CKPT)\n",
        "new_model = load_model(NEW_CKPT)\n",
        "print(\"loaded old/new models\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_mask_with(model, gray_u8, thr=0.5):\n",
        "    H, W = gray_u8.shape\n",
        "    img_pad, (top, left, h, w) = reflect_pad_to(gray_u8, TARGET_SIZE)\n",
        "    prob_canvas = np.zeros((TARGET_SIZE, TARGET_SIZE), dtype=np.float32)\n",
        "\n",
        "    for r in range(TARGET_SIZE // PATCH_SIZE):\n",
        "        for c in range(TARGET_SIZE // PATCH_SIZE):\n",
        "            y0 = r * PATCH_SIZE\n",
        "            x0 = c * PATCH_SIZE\n",
        "            patch = img_pad[y0:y0+PATCH_SIZE, x0:x0+PATCH_SIZE].astype(np.float32) / 255.0\n",
        "            x = torch.from_numpy(patch).unsqueeze(0).unsqueeze(0).to(device)\n",
        "            logits = model(x)\n",
        "            prob = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
        "            prob_canvas[y0:y0+PATCH_SIZE, x0:x0+PATCH_SIZE] = prob\n",
        "\n",
        "    prob_crop = prob_canvas[top:top+h, left:left+w]\n",
        "    mask01 = (prob_crop > thr).astype(np.uint8)\n",
        "    return mask01\n",
        "\n",
        "# -------------------------\n",
        "# run + save\n",
        "# -------------------------\n",
        "rows = []\n",
        "\n",
        "for f1M, f1Y in pairs:\n",
        "    case = f1M.replace(\"_1M.png\", \"\")\n",
        "    img1M = load_gray_u8(os.path.join(ROOT, f1M))\n",
        "    img1Y = load_gray_u8(os.path.join(ROOT, f1Y))\n",
        "\n",
        "    # align 1Y->1M（比較を公平に）\n",
        "    warp_mode = cv2.MOTION_AFFINE\n",
        "    try:\n",
        "        warp, cc = register_ecc(normalize_u8(img1M), normalize_u8(img1Y), warp_mode=warp_mode)\n",
        "        img1Y_aligned = warp_image(img1Y, img1M.shape, warp, warp_mode=warp_mode)\n",
        "    except cv2.error:\n",
        "        warp_mode = cv2.MOTION_HOMOGRAPHY\n",
        "        warp, cc = register_ecc(normalize_u8(img1M), normalize_u8(img1Y), warp_mode=warp_mode)\n",
        "        img1Y_aligned = warp_image(img1Y, img1M.shape, warp, warp_mode=warp_mode)\n",
        "\n",
        "    # masks\n",
        "    oldM = predict_mask_with(old_model, img1M, thr=THR)\n",
        "    oldY = predict_mask_with(old_model, img1Y_aligned, thr=THR)\n",
        "    newM = predict_mask_with(new_model, img1M, thr=THR)\n",
        "    newY = predict_mask_with(new_model, img1Y_aligned, thr=THR)\n",
        "\n",
        "    # areas\n",
        "    rows.append({\n",
        "        \"case\": case,\n",
        "        \"ecc_cc\": cc,\n",
        "        \"warp_mode\": \"AFFINE\" if warp_mode == cv2.MOTION_AFFINE else \"HOMOGRAPHY\",\n",
        "        \"old_area_1M\": int(oldM.sum()),\n",
        "        \"old_area_1Y\": int(oldY.sum()),\n",
        "        \"old_delta\": int(oldY.sum()) - int(oldM.sum()),\n",
        "        \"new_area_1M\": int(newM.sum()),\n",
        "        \"new_area_1Y\": int(newY.sum()),\n",
        "        \"new_delta\": int(newY.sum()) - int(newM.sum()),\n",
        "    })\n",
        "\n",
        "    # save overlay images\n",
        "    Image.fromarray(overlay_on_gray(img1M, oldM, alpha=ALPHA)).save(os.path.join(OUT_DIR, f\"{case}_OLD_1M.png\"))\n",
        "    Image.fromarray(overlay_on_gray(img1Y_aligned, oldY, alpha=ALPHA)).save(os.path.join(OUT_DIR, f\"{case}_OLD_1Y.png\"))\n",
        "    Image.fromarray(overlay_on_gray(img1M, newM, alpha=ALPHA)).save(os.path.join(OUT_DIR, f\"{case}_NEW_1M.png\"))\n",
        "    Image.fromarray(overlay_on_gray(img1Y_aligned, newY, alpha=ALPHA)).save(os.path.join(OUT_DIR, f\"{case}_NEW_1Y.png\"))\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(\"case\")\n",
        "csv_path = os.path.join(OUT_DIR, \"compare_old_vs_new.csv\")\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"saved:\", csv_path)\n",
        "display(df)\n",
        "print(\"overlays saved to:\", OUT_DIR)"
      ],
      "metadata": {
        "id": "l1wLnJMZZo3M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "31bad4cc-16fc-489b-b36a-1d09c47a5552"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "device: cuda\n",
            "loaded old/new models\n",
            "saved: /content/drive/MyDrive/AiFundas/followup_compare_old_vs_new/compare_old_vs_new.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    case    ecc_cc warp_mode  old_area_1M  old_area_1Y  old_delta  \\\n",
              "0    pt1  0.937967    AFFINE      4448419      3849918    -598501   \n",
              "1  pt13R  0.956527    AFFINE      3739003      3232333    -506670   \n",
              "2  pt21R  0.924565    AFFINE      3413336      3619036     205700   \n",
              "3  pt27R  0.963204    AFFINE      3751164      3615668    -135496   \n",
              "\n",
              "   new_area_1M  new_area_1Y  new_delta  \n",
              "0      4578053      4074318    -503735  \n",
              "1      3899164      3575967    -323197  \n",
              "2      3562974      3739858     176884  \n",
              "3      3836357      3692488    -143869  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-975d50c3-55aa-4685-9526-26f32c8d9464\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>case</th>\n",
              "      <th>ecc_cc</th>\n",
              "      <th>warp_mode</th>\n",
              "      <th>old_area_1M</th>\n",
              "      <th>old_area_1Y</th>\n",
              "      <th>old_delta</th>\n",
              "      <th>new_area_1M</th>\n",
              "      <th>new_area_1Y</th>\n",
              "      <th>new_delta</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pt1</td>\n",
              "      <td>0.937967</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>4448419</td>\n",
              "      <td>3849918</td>\n",
              "      <td>-598501</td>\n",
              "      <td>4578053</td>\n",
              "      <td>4074318</td>\n",
              "      <td>-503735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pt13R</td>\n",
              "      <td>0.956527</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3739003</td>\n",
              "      <td>3232333</td>\n",
              "      <td>-506670</td>\n",
              "      <td>3899164</td>\n",
              "      <td>3575967</td>\n",
              "      <td>-323197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pt21R</td>\n",
              "      <td>0.924565</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3413336</td>\n",
              "      <td>3619036</td>\n",
              "      <td>205700</td>\n",
              "      <td>3562974</td>\n",
              "      <td>3739858</td>\n",
              "      <td>176884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pt27R</td>\n",
              "      <td>0.963204</td>\n",
              "      <td>AFFINE</td>\n",
              "      <td>3751164</td>\n",
              "      <td>3615668</td>\n",
              "      <td>-135496</td>\n",
              "      <td>3836357</td>\n",
              "      <td>3692488</td>\n",
              "      <td>-143869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-975d50c3-55aa-4685-9526-26f32c8d9464')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-975d50c3-55aa-4685-9526-26f32c8d9464 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-975d50c3-55aa-4685-9526-26f32c8d9464');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_1616e738-3364-4beb-85ca-7a9a05e66003\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1616e738-3364-4beb-85ca-7a9a05e66003 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"case\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"pt13R\",\n          \"pt27R\",\n          \"pt1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ecc_cc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017607059187582933,\n        \"min\": 0.9245649990767872,\n        \"max\": 0.9632039814472902,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9565268482844995,\n          0.9632039814472902,\n          0.9379669885098603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"warp_mode\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AFFINE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"old_area_1M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 436001,\n        \"min\": 3413336,\n        \"max\": 4448419,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3739003\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"old_area_1Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 255943,\n        \"min\": 3232333,\n        \"max\": 3849918,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3232333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"old_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 368691,\n        \"min\": -598501,\n        \"max\": 205700,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -506670\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_area_1M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 431382,\n        \"min\": 3562974,\n        \"max\": 4578053,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3899164\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_area_1Y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 213832,\n        \"min\": 3575967,\n        \"max\": 4074318,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3575967\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"new_delta\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 290181,\n        \"min\": -503735,\n        \"max\": 176884,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          -323197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overlays saved to: /content/drive/MyDrive/AiFundas/followup_compare_old_vs_new\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dicmwaaIDNRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T6A3aV74DNUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bsIiKKRyDNWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}